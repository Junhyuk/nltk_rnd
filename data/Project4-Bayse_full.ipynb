{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **나이브베이즈 모델의 활용**\n",
    "1. **베이지안 평가 학습모델**을 불러온다 (0:부정 / 1:긍정)\n",
    "1. **분석을 위한 네이버 뉴스 댓글**을 수집한다 (600개 내외가 적합)\n",
    "1. **긍정/ 부정 댓글**을 분류한다\n",
    "1. **긍정 리뷰**의 **Token** 을 트위터 **Stemming**으로 정규화 한다\n",
    "1. **정규화된 Token** 중 **\"명사\", \"동사\", \"형용사\"** 만 수집\n",
    "1. 수집된 Token List 객체를 **nltk.Text 로 변환 후 빈도상위 10개**를 출력한다\n",
    "\n",
    "<img src=\"http://www.meconomynews.com/news/photo/201806/15255_14549_2116.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **1 모듈과 데이터 불러오기**\n",
    "Import Data / Datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x7f004ef9bda0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 : 앞에서 학습한 Classifier 모델을 불러온다\n",
    "# >> classifier = pickle.\n",
    "\n",
    "import pickle\n",
    "file = './data/classifiers.model'\n",
    "classifier = pickle.load(open(file, 'rb'))\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Punctuation', '하다/Verb', '영화/Noun', '이/Josa', '보다/Verb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2 : 분류기준 단어목록 불러오기\n",
    "# >> selected_words = pickle.\n",
    "\n",
    "file = './data/selected.words'\n",
    "selected_words = pickle.load(open(file, 'rb'))\n",
    "selected_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Tokenizer 생성/ 판단모듈\n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "# 문단을 긍부정 분석용 Token 생성하기\n",
    "def tokenize(doc):\n",
    "    doc = ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "    return {'exists({})'.format(word): (word in set(doc)) for word in selected_words}\n",
    "\n",
    "# 위에서 생성한 Token을 활용하여 판단하기\n",
    "def classify_text(text):\n",
    "    tokens = tokenize(text)             # 트위터로 Stemming/ Taggging 후 Selected_word 판단결과 객체\n",
    "    return classifier.classify(tokens)  # 분류모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 : 데이터와 모델, 함수를 활용하여 긍/부정 Test\n",
    "# 0 : 부정모델 , 1 : 긍정모델\n",
    "\n",
    "text   = \"\"\"영화가 재미있어요\"\"\"\n",
    "classify_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **2 뉴스 데이터 댓글데이터 불러오기**\n",
    "replies [참고](http://blog.naver.com/PostView.nhn?blogId=sangdo14&logNo=220610607049&categoryNo=0&parentCategoryNo=163&viewDate=&currentPage=1&postListTopCurrentPage=1&from=search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length : 116\n",
      "Data sample : ['\"경제대국들의 무역전쟁이 이정도군. 한국정부는 돈이 너무 많아서 50조정도는 허공에 날리고 어디에 썼는지 데이타조차 없는데.\"', '\"이제 좀 제대로 보네.. 뭐만 하면 11월 중간선거 때문에, 러시아스캔들때문에, 정치적으로 위기에 몰린 트럼프가 할수없이 자폭무역전쟁..별 희안한 기사만 써대더니..ㅉㅉ\"', '\"짱깨 뒷돈 받아 처먹은 참여련대, 청와대 주사파들, 그리고 한경오 쓰레기 언론들 어쩌냐ㅋㅋㅋㅋㅋ\"', '\"트럼프형 머찜. 찌질이 시진핑 더 밟아라.\"', '\"문빨충 좌좀들아. 니들의 큰 아버지황제 시진핑이 위험하다. 어서 광화문에 모여서 좃불 좀비집회 해야지? 니들이 물고빠는 문재앙이 추앙하는 중국의 황제가 뚜까맞고 있자나! 어서 가서 좃불을 밝히세요\"']\n"
     ]
    }
   ],
   "source": [
    "from txtutil import Naver_news_rep\n",
    "news_url = \"https://news.naver.com/main/ranking/read.nhn?rankingType=popular_day&\" +\\\n",
    "    \"oid=001&aid=0010299155&date=20180827&type=1&rankingSectionId=101&rankingSeq=30\"\n",
    "    \n",
    "data = Naver_news_rep(news_url)\n",
    "print(\"Data length : {}\\nData sample : {}\".format(\n",
    "    len(data), data[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://news.naver.com/main/ranking/read.nhn?rankingType=popular_day&oid=001&aid=0010299155&date=20180827&type=1&rankingSectionId=101&rankingSeq=30'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **Mission Test**\n",
    "긍정 부정댓글 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 1\n",
    "# 전체 댓글 갯수중 긍정/ 부정 갯수 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro, con = [], []\n",
    "for datum in data:\n",
    "    if classify_text(datum) == \"1\":\n",
    "        pro.append(datum)\n",
    "    else:\n",
    "        con.append(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result[\"긍정\"] = pro\n",
    "result[\"부정\"] = con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"긍정\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"부정\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 2\n",
    "# 긍정 댓글을 구분하여 분류한 뒤\n",
    "# 명사, 형용사, 동사 Token만 추출하기 (전처리 / Token의 예외처리는 미포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable         Type                    Data/Info\n",
      "--------------------------------------------------\n",
      "Naver_news_rep   function                <function Naver_news_rep at 0x7fa986f55840>\n",
      "Twitter          type                    <class 'konlpy.tag._twitter.Twitter'>\n",
      "classifier       NaiveBayesClassifier    <nltk.classify.naivebayes<...>object at 0x7fa9bc1bd9b0>\n",
      "classify_text    function                <function classify_text at 0x7fa986f559d8>\n",
      "con              list                    n=80\n",
      "data             list                    n=121\n",
      "datum            str                     \"아이고 중국이 그따위 모르고 전쟁 했는줄아냐<...>래라 개소리한다고 누깜짝 하는나라가 아니다.\"\n",
      "file             str                     ./data/selected.words\n",
      "news_url         str                     https://news.naver.com/ma<...>ctionId=101&rankingSeq=30\n",
      "pickle           module                  <module 'pickle' from '/u<...>lib/python3.6/pickle.py'>\n",
      "pro              list                    n=41\n",
      "result           dict                    n=2\n",
      "selected_words   list                    n=4000\n",
      "text             str                     영화가 별로입니다 비추합니다\n",
      "tokenize         function                <function tokenize at 0x7fa986b83048>\n",
      "twitter          Twitter                 <konlpy.tag._twitter.Twit<...>object at 0x7fa987973780>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"트럼프형 머찜. 찌질이 시진핑 더 밟아라.\"',\n",
       " '\"중국은  지금  확실하게  조지지  않으면  훗날  미국 최대의  위협국이  된다,,,,,!!!!!!!!!!!!!!!!!!\"',\n",
       " '\"중국은 하나의 중국이 아니라 10개의 중국으로 나눠져야한다  큰 땅에 여러민족이 있다 그중하나로 요동 지방은 고조선이라는 나라도 분리독립해야한다\"']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = result['긍정']\n",
    "texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\"', 'Punctuation'), ('중국', 'Noun'), ('은', 'Josa'), ('하나', 'Noun'), ('의', 'Josa'), ('중국', 'Noun'), ('이', 'Josa'), ('아니다', 'Adjective'), ('10', 'Number'), ('개', 'Noun'), ('의', 'Josa'), ('중국', 'Noun'), ('으로', 'Josa'), ('나누다', 'Verb'), ('야하다', 'Adjective'), ('크다', 'Verb'), ('땅', 'Noun'), ('에', 'Josa'), ('여러', 'Noun'), ('민족', 'Noun'), ('이', 'Josa'), ('있다', 'Adjective'), ('그중', 'Adverb'), ('하나로', 'Noun'), ('요동', 'Noun'), ('지방', 'Noun'), ('은', 'Josa'), ('고조선', 'Noun'), ('이라는', 'Josa'), ('나라', 'Noun'), ('도', 'Josa'), ('분리', 'Noun'), ('독립', 'Noun'), ('하다', 'Verb'), ('하다', 'Verb'), ('\"', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter.pos(texts[2], stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중국\n",
      "하나\n",
      "중국\n",
      "중국\n",
      "여러\n",
      "민족\n",
      "하나로\n",
      "요동\n",
      "지방\n",
      "고조선\n",
      "나라\n",
      "분리\n",
      "독립\n"
     ]
    }
   ],
   "source": [
    "for token in twitter.pos(texts[2], stem=True):\n",
    "    if (token[1] == 'Noun') and (len(token[0]) >1):\n",
    "        print(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = result['긍정']\n",
    "filtered_tokens = []\n",
    "for text in texts:\n",
    "    tokens = twitter.pos(text ,stem=True)\n",
    "    tokens = [token[0]    for token in tokens    \n",
    "                          if (token[1] in ['Noun','Adjective','Verb']) and (len(token[0]) > 1 )]\n",
    "    filtered_tokens += tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 3\n",
    "# nltk.Text() 객체를 활용하기\n",
    "# 상위 빈도수 50인 Token을 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('하다', 32),\n",
       " ('트럼프', 16),\n",
       " ('중국', 15),\n",
       " ('미국', 14),\n",
       " ('되다', 10),\n",
       " ('한국', 7),\n",
       " ('있다', 6),\n",
       " ('전쟁', 6),\n",
       " ('시진핑', 5),\n",
       " ('짱깨', 5),\n",
       " ('조선시대', 5),\n",
       " ('민족', 4),\n",
       " ('잡다', 4),\n",
       " ('화이팅', 4),\n",
       " ('좋다', 4),\n",
       " ('들다', 4),\n",
       " ('무역', 4),\n",
       " ('우리', 4),\n",
       " ('지금', 3),\n",
       " ('아니다', 3)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "pos_nltk = nltk.Text(filtered_tokens, name='긍정댓글')\n",
    "pos_nltk.vocab().most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **nltk 객체 활용하기**\n",
    "Token 주변의 단어들 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      " 역사 잊다 민족 미래 없다 하다 일제강점기 하다 중국 식민지 이다 조선시대 관심 없다 나라 조선시대 인조 배금 정책 보다 같다 중국 조공 바치\n",
      "다 하다 일제강점기 하다 중국 식민지 이다 조선시대 관심 없다 나라 조선시대 인조 배금 정책 보다 같다 중국 조공 바치 국민 노예 삼다 풍악 즐\n",
      " 배금 정책 보다 같다 중국 조공 바치 국민 노예 삼다 풍악 즐기다 조선시대 아마 기득권 세력 볼땐 조선시대 말로 살기 좋다 세상 아니다 싶다 \n",
      " 바치 국민 노예 삼다 풍악 즐기다 조선시대 아마 기득권 세력 볼땐 조선시대 말로 살기 좋다 세상 아니다 싶다 역사 기억 하다 민족 생각 하다 \n",
      " 살기 좋다 세상 아니다 싶다 역사 기억 하다 민족 생각 하다 미래 조선시대 같다 지금 전쟁 있다 무역 분쟁 보다 아침 시원하다 뉴스 트럼프 응\n"
     ]
    }
   ],
   "source": [
    "pos_nltk.concordance('조선시대')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
