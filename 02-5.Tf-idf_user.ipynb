{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **tf-idf**\n",
    "\n",
    "## **1 tf - idf 를 직접 구현하기**\n",
    "사용자 함수를 사용하여 tf-idf 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 계산을 위한 공식을 사용자가 직접 구현\n",
    "# tf-idf('Token' , '분석 Document' , '모집단 Document 의 Token 목록')\n",
    "\n",
    "from txtutil import tf_idf\n",
    "tf_idf('it', 'it can it it', ['can', 'can', 'can', 'it', 'it', 'it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 자료를 가져온다\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_eng = stopwords.words('english') +\\\n",
    "                ['samsung','krw','quarter','full','year']\n",
    "stopwords_eng[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **2 idf : Docs 대상문서들 목록 추출하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document 자료 불러오기\n",
    "from glob import glob\n",
    "filelist    = glob('./data/News201*.txt')\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document -> Filtering(Stopwords) -> token 추출\n",
    "import re\n",
    "docs_tokens = []\n",
    "\n",
    "for file in filelist:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        texts = f.read()\n",
    "        \n",
    "    # Document 전처리 작업을 진행\n",
    "    texts     = texts.lower()\n",
    "    texts     = texts.replace('\\n', ' ')\n",
    "    tokenizer = re.compile(r'[a-z]\\w+') # 영단어 추출\n",
    "    tokens    = tokenizer.findall(texts)    \n",
    "    tokens    = [token  for token in tokens   \n",
    "                 if (len(token) > 2) and (token not in stopwords_eng)]\n",
    "    docs_tokens += tokens\n",
    "    \n",
    "docs_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출한 Token의 빈도를 계산\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "pd.Series(FreqDist(docs_tokens)).sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **3 tf : Doc 대상문서에서 Token 추출하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1 : Document 불러오기\n",
    "with open('./data/News2017.txt', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    texts = texts.lower()\n",
    "\n",
    "# Step2 : Token 추출\n",
    "texts     = texts.replace('\\n', ' ')\n",
    "tokenizer = re.compile(r'[a-z]\\w+')\n",
    "tokens    = tokenizer.findall(texts)\n",
    "\n",
    "# Step3 : Filtering(stopwords) 알파벳 2글자 이상인 단어를 대상\n",
    "tokens = [token  for token in tokens   \n",
    "                 if (len(token) > 2) and (token not in stopwords_eng)]\n",
    "token_string = \" \".join(tokens)\n",
    "token_string[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **4 tf-idf 를 계산**\n",
    "위에서 추출한 idf 정보와, tf 정보를 활용하여 tf-idf를 측정/ 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "token_set   = list(set(tokens))\n",
    "result_dict = {}\n",
    "\n",
    "# tf-idf 계산결과를 출력한다\n",
    "for txt in token_set:\n",
    "    result_dict[txt] = tf_idf(txt, token_string, docs_tokens)\n",
    "    \n",
    "print('Calculating is Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 결과를 Pandas로 출력\n",
    "import pandas as pd\n",
    "tfidf = pd.Series(result_dict)\n",
    "tfidf.sort_values(ascending=False)[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
