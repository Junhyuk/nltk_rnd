{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **나이브베이즈 모델의 활용**\n",
    "1. **베이지안 평가 학습모델**을 불러온다 (0:부정 / 1:긍정)\n",
    "1. **분석을 위한 네이버 뉴스 댓글**을 수집한다 (600개 내외가 적합)\n",
    "1. **긍정/ 부정 댓글**을 분류한다\n",
    "1. **긍정 리뷰**의 **Token** 을 트위터 **Stemming**으로 정규화 한다\n",
    "1. **정규화된 Token** 중 **\"명사\", \"동사\", \"형용사\"** 만 수집\n",
    "1. 수집된 Token List 객체를 **nltk.Text 로 변환 후 빈도상위 10개**를 출력한다\n",
    "\n",
    "<img src=\"http://www.meconomynews.com/news/photo/201806/15255_14549_2116.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **1 모듈과 데이터 불러오기**\n",
    "Import Data / Datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : 앞에서 학습한 Classifier 모델을 불러온다\n",
    "# >> classifier = pickle.\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : 분류기준 단어목록 불러오기\n",
    "# >> selected_words = pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Tokenizer 생성/ 판단모듈\n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "# 문단을 긍부정 분석용 Token 생성하기\n",
    "def tokenize(doc):\n",
    "    doc = ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "    return {'exists({})'.format(word): (word in set(doc)) for word in selected_words}\n",
    "\n",
    "# 위에서 생성한 Token을 활용하여 판단하기\n",
    "def classify_text(text):\n",
    "    tokens = tokenize(text)             # 트위터로 Stemming/ Taggging 후 Selected_word 판단결과 객체\n",
    "    return classifier.classify(tokens)  # 분류모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 : 데이터와 모델, 함수를 활용하여 긍/부정 Test\n",
    "# 0 : 부정모델 , 1 : 긍정모델\n",
    "\n",
    "# text   = \"\"\"영화가 재미있어요\"\"\"\n",
    "# classify_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **2 뉴스 데이터 댓글데이터 불러오기**\n",
    "replies [참고](http://blog.naver.com/PostView.nhn?blogId=sangdo14&logNo=220610607049&categoryNo=0&parentCategoryNo=163&viewDate=&currentPage=1&postListTopCurrentPage=1&from=search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from txtutil import Naver_news_rep\n",
    "# news_url = \"https://news.naver.com/main/hotissue/read.nhn?mid=hot&\" +\\\n",
    "#            \"sid1=&cid=1064721&iid=3227816&oid=001&aid=0010068060&ptype=021\"\n",
    "# replies  = Naver_news_rep(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 뉴스 댓글이 저장 된\n",
    "# './data/naver_news.rep' 데이터를\n",
    "# data 매개변수로 불러오기\n",
    "\n",
    "import pickle\n",
    "\n",
    "# print(\"Data length : {}\\nData sample : {}\".format(\n",
    "#     len(data), data[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **Mission Test**\n",
    "긍정 부정댓글 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 1\n",
    "# 전체 댓글 갯수중 긍정/ 부정 갯수 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro, con = [], []\n",
    "for datum in data:\n",
    "    if classify_text(datum) == \"1\":\n",
    "        pro.append(datum)\n",
    "    else:\n",
    "        con.append(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result[\"긍정\"] = pro\n",
    "result[\"부정\"] = con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[\"긍정\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[\"부정\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 2\n",
    "# 긍정 댓글을 구분하여 분류한 뒤\n",
    "# 명사, 형용사, 동사 Token만 추출하기 (전처리 / Token의 예외처리는 미포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = result['부정']\n",
    "texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = []\n",
    "for text in texts:\n",
    "    tokens = twitter.pos(text ,stem=True)\n",
    "    tokens = [token[0]    for token in tokens    \n",
    "                          if (token[1] in ['Noun','Adjective','Verb']) and (len(token[0]) > 1 )]\n",
    "    filtered_tokens += tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mission 3\n",
    "# nltk.Text() 객체를 활용하기\n",
    "# 상위 빈도수 50인 Token을 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "pos_nltk = nltk.Text(filtered_tokens, name='부정댓글')\n",
    "pos_nltk.vocab().most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **nltk 객체 활용하기**\n",
    "Token 주변의 단어들 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_nltk.concordance('갤럭시')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
